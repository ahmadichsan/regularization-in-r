% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\author{}
\date{\vspace{-2.5em}}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\begin{document}

\textbf{Homework Day 20}

\textbf{Author: Ahmad Ichsan Baihaqi}

\textbf{Email:
\href{mailto:ahmadichsanbaihaqi@gmail.com}{\nolinkurl{ahmadichsanbaihaqi@gmail.com}}}

In this task, we will use housing price in boston as the dataset. The
objective of this task is to create linear regression model with
regularization using Ridge and Lasso.

\hypertarget{load-dataset}{%
\section{Load dataset}\label{load-dataset}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"boston.csv"}\NormalTok{)}

\FunctionTok{head}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat
## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98
## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14
## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03
## 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94
## 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33
## 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21
##   medv
## 1 24.0
## 2 21.6
## 3 34.7
## 4 33.4
## 5 36.2
## 6 28.7
\end{verbatim}

\hypertarget{determine-data-type-of-each-feature}{%
\section{Determine data type of each
feature}\label{determine-data-type-of-each-feature}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sapply}\NormalTok{(data, class)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      crim        zn     indus      chas       nox        rm       age       dis 
## "numeric" "numeric" "numeric" "integer" "numeric" "numeric" "numeric" "numeric" 
##       rad       tax   ptratio     black     lstat      medv 
## "integer" "integer" "numeric" "numeric" "numeric" "numeric"
\end{verbatim}

Based on above observation, we can take insight: 1. There are 14
features in this dataset 2. Those features are: a. Criminal rate (crim)
b. Residential land zoned proportion (zn) c.~Non-retail business acres
proportion (indus) d.~Is bounds with river (chas) e. Nitrogen oxides
concentration (nox) f.~Number rooms average (rm) g. Owner age proportion
(age) h. Weighted distance to cities (dis) i. Accessibility index (rad)
l. Tax rate (tax) m. Pupil-teacher ratio (ptratio) n.~Black proportion
(black) o. Percent lower status (lstat) p.~housing price (medv) 3. Our
target feature is the housing price (medv) 4. No categorical feature, so
we don't have to do encoding

Before we start, let's check if there is any missing value in this
dataset.

\hypertarget{finding-missing-value}{%
\section{Finding missing value}\label{finding-missing-value}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sapply}\NormalTok{(data, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(x)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    crim      zn   indus    chas     nox      rm     age     dis     rad     tax 
##       0       0       0       0       0       0       0       0       0       0 
## ptratio   black   lstat    medv 
##       0       0       0       0
\end{verbatim}

Fortunately, there is no missing value in our dataset.

\hypertarget{splitting-data}{%
\section{Splitting data}\label{splitting-data}}

First thing we have to do is to split our dataset into three parts: a.
80\% of original dataset will be devided into: 1. train: 80\% from the
80\% of the original dataset 2. validate: 20\% from the 80\% of the
original dataset

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  20\% of original dataset will be devided into:
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  test: 100\% from 20\% of the original dataset
\end{enumerate}

\hypertarget{note-about-validation-set}{%
\subsection{Note about validation set}\label{note-about-validation-set}}

The validation set is a set of data, separate from the training set,
that is used to validate our model performance during training.

This validation process gives information that helps us tune the model's
hyperparameters and configurations accordingly. It is like a critic
telling us whether the training is moving in the right direction or not.

The model is trained on the training set, and, simultaneously, the model
evaluation is performed on the validation set after every epoch.

The main idea of splitting the dataset into a validation set is to
prevent our model from overfitting i.e., the model becomes really good
at classifying the samples in the training set but cannot generalize and
make accurate classifications on the data it has not seen before.

reference: \url{https://www.v7labs.com/blog/train-validation-test-set}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caTools)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Split data into 3 parts}
\CommentTok{\# train {-} validation {-} test}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\CommentTok{\# split 80\% (SAMPLE TRUE) : 20\% (SAMPLE FALSE) from original dataset}
\NormalTok{sample }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{medv, }\AttributeTok{SplitRatio =}\NormalTok{ .}\DecValTok{80}\NormalTok{)}

\CommentTok{\# stored 80\% (SAMPLE TRUE) of the dataset into one variable}
\CommentTok{\# which later will be used as the total 100\% of train and validation set}
\NormalTok{pre\_train }\OtherTok{=} \FunctionTok{subset}\NormalTok{(data, sample }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# split 80\% (SAMPLE TRAIN TRUE) : 20\% (SAMPLE TRAIN FALSE) from the pre\_train}
\NormalTok{sample\_train }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(pre\_train}\SpecialCharTok{$}\NormalTok{medv, }\AttributeTok{SplitRatio =}\NormalTok{ .}\DecValTok{80}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# train{-}validation data}

\CommentTok{\# stored 80\% (SAMPLE TRAIN TRUE) of the dataset into one variable}
\NormalTok{train }\OtherTok{=} \FunctionTok{subset}\NormalTok{(pre\_train, sample\_train }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# stored 20\% (SAMPLE TRAIN FALSE) of the dataset into one variable}
\NormalTok{validation }\OtherTok{=} \FunctionTok{subset}\NormalTok{(pre\_train, sample\_train }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# test data}

\CommentTok{\# stored 20\% (SAMPLE FALSE) of the dataset into one variable}
\NormalTok{test }\OtherTok{=} \FunctionTok{subset}\NormalTok{(data, sample }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{correlation-features-plot-on-training-dataset}{%
\section{Correlation features plot on training
dataset}\label{correlation-features-plot-on-training-dataset}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(psych)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairs.panels}\NormalTok{(}
\NormalTok{  train,}
  \AttributeTok{method =} \StringTok{"pearson"}\NormalTok{, }\CommentTok{\# correlation method}
  \AttributeTok{hist.col =} \StringTok{"\#00AFBB"}\NormalTok{,}
  \AttributeTok{density =} \ConstantTok{TRUE}\NormalTok{,  }\CommentTok{\# show density plots}
  \AttributeTok{ellipses =} \ConstantTok{TRUE} \CommentTok{\# show correlation ellipses}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{HW_DAY20_AHMAD_ICHSAN_BAIHAQI_files/figure-latex/unnamed-chunk-9-1.pdf}

Condition: 1. Threshold for high correlation is if the absolute(corr)
\textgreater= 0.8

Insight: 1. The only feature correlation which satisfied our above
condition is a correlation between rad and tax, which is 0.90. 2. To
avoid multicollinearity, we need to drop one of this feature. 3. Between
rad and medv, it has correlation coef -0.45 4. Between tax and medv, it
has correlation coef -0.56 5. Feature that we should keep is a feature
which has highest absolute(corr) with our target feature (medv). In this
case, we should keep tax and drop rad feature.

\hypertarget{dropping-feature}{%
\section{Dropping feature}\label{dropping-feature}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'dplyr'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     filter, lag
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# drop correlated columns}
\NormalTok{drop\_cols }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}rad\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\OtherTok{=}\NormalTok{ train }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{drop\_cols)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Note: Using an external vector in selections is ambiguous.
## i Use `all_of(drop_cols)` instead of `drop_cols` to silence this message.
## i See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.
## This message is displayed once per session.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{validation }\OtherTok{=}\NormalTok{ validation }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{drop\_cols)}
\NormalTok{test }\OtherTok{=}\NormalTok{ test }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{drop\_cols)}
\end{Highlighting}
\end{Shaded}

\hypertarget{fit-models-on-training-data}{%
\section{Fit models on training
data}\label{fit-models-on-training-data}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# feature preprocessing}
\CommentTok{\# to ensure we handle categorical features}
\NormalTok{x }\OtherTok{=} \FunctionTok{model.matrix}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., train)[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]}
\NormalTok{y }\OtherTok{=}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{medv}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(glmnet)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: Matrix
\end{verbatim}

\begin{verbatim}
## Loaded glmnet 4.1-3
\end{verbatim}

\hypertarget{ridge-regression}{%
\subsection{Ridge regression}\label{ridge-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit multiple ridge regression with different lambda}
\CommentTok{\# lambda = [0.01, 0.1, 1, 10]}
\NormalTok{ridge\_reg\_pointzeroone }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =} \FloatTok{0.01}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(ridge\_reg\_pointzeroone)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                        s0
## (Intercept)  2.807966e+01
## crim        -7.972347e-02
## zn           3.796482e-02
## indus       -4.106178e-02
## chas         2.893259e+00
## nox         -1.602703e+01
## rm           4.517287e+00
## age          5.679736e-03
## dis         -1.314253e+00
## tax         -2.421124e-04
## ptratio     -9.031044e-01
## black        6.572154e-03
## lstat       -4.779743e-01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ridge\_reg\_pointone }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =} \FloatTok{0.1}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(ridge\_reg\_pointone)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                        s0
## (Intercept)  2.720583e+01
## crim        -7.865999e-02
## zn           3.682165e-02
## indus       -4.208117e-02
## chas         2.888898e+00
## nox         -1.513326e+01
## rm           4.524625e+00
## age          5.018603e-03
## dis         -1.260076e+00
## tax         -4.973179e-04
## ptratio     -8.931536e-01
## black        6.639672e-03
## lstat       -4.709285e-01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ridge\_reg\_one }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{1}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(ridge\_reg\_one)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                      s0
## (Intercept) 22.53185712
## crim        -0.07288298
## zn           0.02967177
## indus       -0.05282228
## chas         2.84365458
## nox         -9.91885353
## rm           4.44323173
## age          0.00101080
## dis         -0.90469612
## tax         -0.00195283
## ptratio     -0.82592673
## black        0.00688591
## lstat       -0.41785676
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ridge\_reg\_ten }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{10}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(ridge\_reg\_ten)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                       s0
## (Intercept) 21.798954932
## crim        -0.061446034
## zn           0.020349479
## indus       -0.081406215
## chas         2.105932529
## nox         -4.343751697
## rm           2.889836712
## age         -0.008076179
## dis         -0.190031642
## tax         -0.003586798
## ptratio     -0.571970624
## black        0.005615501
## lstat       -0.242577448
\end{verbatim}

\hypertarget{lasso-regression}{%
\section{Lasso regression}\label{lasso-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit multiple lasso regression with different lambda}
\CommentTok{\# lambda = [0.01, 0.1, 1, 10]}
\NormalTok{lasso\_reg\_pointzeroone }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =} \FloatTok{0.01}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(lasso\_reg\_pointzeroone)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                        s0
## (Intercept)  2.782960e+01
## crim        -7.879101e-02
## zn           3.673332e-02
## indus       -3.849552e-02
## chas         2.864983e+00
## nox         -1.574647e+01
## rm           4.531757e+00
## age          4.411184e-03
## dis         -1.294476e+00
## tax         -2.439776e-04
## ptratio     -9.039250e-01
## black        6.556538e-03
## lstat       -4.764532e-01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso\_reg\_pointone }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =} \FloatTok{0.1}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(lasso\_reg\_pointone)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                        s0
## (Intercept)  2.472929e+01
## crim        -6.891240e-02
## zn           2.563768e-02
## indus       -1.728300e-02
## chas         2.590973e+00
## nox         -1.267687e+01
## rm           4.620427e+00
## age          .           
## dis         -1.022117e+00
## tax         -5.088209e-04
## ptratio     -9.019518e-01
## black        6.368681e-03
## lstat       -4.677220e-01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso\_reg\_one }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{1}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(lasso\_reg\_one)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                       s0
## (Intercept) 13.987998322
## crim        -0.010183404
## zn           .          
## indus        .          
## chas         .          
## nox          .          
## rm           4.306536549
## age          .          
## dis          .          
## tax         -0.000775465
## ptratio     -0.710899295
## black        0.001632894
## lstat       -0.457861803
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso\_reg\_ten }\OtherTok{=} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{10}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(lasso\_reg\_ten)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13 x 1 sparse Matrix of class "dgCMatrix"
##                   s0
## (Intercept) 22.53775
## crim         0.00000
## zn           .      
## indus        .      
## chas         .      
## nox          .      
## rm           .      
## age          .      
## dis          .      
## tax          .      
## ptratio      .      
## black        .      
## lstat        .
\end{verbatim}

\hypertarget{choose-best-lambda}{%
\section{Choose best lambda}\label{choose-best-lambda}}

The best lambda is when the RMSE value is the smallest among the other
models.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Make predictions on the validation data}
\NormalTok{x\_validation }\OtherTok{=} \FunctionTok{model.matrix}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{., validation)[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]}
\NormalTok{y\_validation }\OtherTok{=}\NormalTok{ validation}\SpecialCharTok{$}\NormalTok{medv}
\end{Highlighting}
\end{Shaded}

\hypertarget{choose-best-lambda-with-ridge-regression}{%
\subsection{Choose best lambda with ridge
regression}\label{choose-best-lambda-with-ridge-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_ridge\_pointzeroone }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(ridge\_reg\_pointzeroone, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_ridge\_pointzeroone }\CommentTok{\# 4.3464 =\textgreater{} best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.3464
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_ridge\_pointone }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(ridge\_reg\_pointone, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_ridge\_pointone }\CommentTok{\# 4.349494}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.349494
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_ridge\_one }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(ridge\_reg\_one, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_ridge\_one }\CommentTok{\# 4.422032}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.422032
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_ridge\_ten }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(ridge\_reg\_ten, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_ridge\_ten }\CommentTok{\# 5.342122}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.342122
\end{verbatim}

Insight: 1. Best lambda using ridge regression is 0.01 with RMSE value
4.3464 2. The model based on the best lambda for predicting the housing
price with ridge regression is:

medv = 27.82960 - 0.07879101 crim + 0.03673332 zn - 0.03849552 indus +
2.864983 chas - 0.1574647 nox + 4.531757 rm + 0.004411184 age - 1.294476
dis - 0.0002439776 tax - 0.9039250 ptratio + 0.006556538 black -
0.4764532 lstat

Model interpretation: 1. If the value for all predictors is zero, the
mdev value is equal to the intercept of the model, which is 27.82960 2.
An increase of 1 point in crim, while the other features are kept fixed,
is associated with a decrease of 0.07879101 in medv. This is make sense
since crim represent criminal rate. Higher criminal rate will decrease
the housing price (medv) 3. An increase of 1 point in chas, while the
other features are kept fixed, is associated with an increase of
2.864983 in medv. This indicate that house which bound with river will
probably has higher housing price. 4. Based on interpretation on point 2
and 3, if we take a little conclusion based on some of the feature (crim
and chas), a house will have higher price if the house located in a low
criminal rate area and bound with a river.

\hypertarget{choose-best-lambda-with-lasso-regression}{%
\subsection{Choose best lambda with lasso
regression}\label{choose-best-lambda-with-lasso-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_lasso\_pointzeroone }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(lasso\_reg\_pointzeroone, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_lasso\_pointzeroone }\CommentTok{\# 4.340783 =\textgreater{} best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.340783
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_lasso\_pointone }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(lasso\_reg\_pointone, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_lasso\_pointone }\CommentTok{\# 4.352728}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.352728
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_lasso\_one }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(lasso\_reg\_one, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_lasso\_one }\CommentTok{\# 4.937774}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.937774
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE\_lasso\_ten }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_validation }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(lasso\_reg\_ten, x\_validation))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_lasso\_ten }\CommentTok{\# 9.371755}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9.371755
\end{verbatim}

Insight: 1. Best lambda using lasso regression is 0.01 with RMSE value
4.340783 (pretty closed with ridge regression) 2. The model based on the
best lambda for predicting the housing price with ridge regression is:

medv = 27.82960 - 0.07879101 crim + 0.03673332 zn - 0.03849552 indus +
2.864983 chas - 0.1574647 nox + 4.531757 rm + 0.004411184 age - 1.294476
dis - 0.0002439776 tax - 0.9039250 ptratio + 0.006556538 black -
0.4764532 lstat

Model interpretation: 1. despite of having different RMSE value between
lasso and ridge with the same lambda (0.01), they both have same coeff
for each feature. Thus, they both have same model with lambda 0.01.

\hypertarget{evaluate-the-best-models-on-the-test-data}{%
\section{Evaluate the best models on the test
data}\label{evaluate-the-best-models-on-the-test-data}}

\hypertarget{create-the-test-value}{%
\subsection{Create the test value}\label{create-the-test-value}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_test }\OtherTok{=} \FunctionTok{model.matrix}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{., test)[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]}
\NormalTok{y\_test }\OtherTok{=}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{medv}
\end{Highlighting}
\end{Shaded}

\hypertarget{evaluate-with-ridge}{%
\subsection{Evaluate with ridge}\label{evaluate-with-ridge}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# RMSE}
\NormalTok{RMSE\_ridge\_best }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_test }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(ridge\_reg\_pointzeroone, x\_test))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_ridge\_best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6.820639
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# MAE}
\NormalTok{MAE\_ridge\_best }\OtherTok{=} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(y\_test}\SpecialCharTok{{-}}\FunctionTok{predict}\NormalTok{(ridge\_reg\_pointzeroone, x\_test)))}
\NormalTok{MAE\_ridge\_best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.896186
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# MAPE}
\NormalTok{MAPE\_ridge\_best }\OtherTok{=} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{((}\FunctionTok{predict}\NormalTok{(ridge\_reg\_pointzeroone, x\_test) }\SpecialCharTok{{-}}\NormalTok{ y\_test))}\SpecialCharTok{/}\NormalTok{y\_test)}
\NormalTok{MAPE\_ridge\_best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1710101
\end{verbatim}

Interpretation: 1. Best result for RMSE with train data using ridge
(\texttt{ridge\_reg\_pointzeroone}) is 4.3464. Meanwhile, when we are
using the test dataset, the RMSE value is quite far, which is 6.82 (the
distance is two points). Is this indicate that our model overfitting?
After googling for a while, unfortunately I couldn't find a reference
which declared the treshold for delta to be considered as overfit. The
only reference I found is this discussion
\url{https://stats.stackexchange.com/questions/497050/how-big-a-difference-for-test-train-rmse-is-considered-as-overfit\#comment919735_497050}
which said that there are no treshold to be considered as overfit.

\hypertarget{evaluate-with-lasso}{%
\subsection{Evaluate with lasso}\label{evaluate-with-lasso}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# RMSE}
\NormalTok{RMSE\_lasso\_best }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((y\_test }\SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(lasso\_reg\_pointzeroone, x\_test))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{RMSE\_lasso\_best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6.823445
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# MAE}
\NormalTok{MAE\_lasso\_best }\OtherTok{=} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(y\_test}\SpecialCharTok{{-}}\FunctionTok{predict}\NormalTok{(lasso\_reg\_pointzeroone, x\_test)))}
\NormalTok{MAE\_lasso\_best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.888415
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# MAPE}
\NormalTok{MAPE\_lasso\_best }\OtherTok{=} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{((}\FunctionTok{predict}\NormalTok{(lasso\_reg\_pointzeroone, x\_test) }\SpecialCharTok{{-}}\NormalTok{ y\_test))}\SpecialCharTok{/}\NormalTok{y\_test)}
\NormalTok{MAPE\_lasso\_best}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1707025
\end{verbatim}

\end{document}
